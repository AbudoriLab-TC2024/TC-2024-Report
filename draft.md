# アーギュメント：3DLiDARの自律走行環境は揃っている
# アカデミックな価値：つくちゃれレポートを読んでも初学者は自律走行できない

# はじめに
* つくばチャレンジは2024年のロボット大賞に選出された
   * つくばチャレンジは18年間，課題や取り組みを変えながら日本のロボット技術の進歩に大きく貢献してきた
   * さまざまな研究者に大体的に実験できる環境を提供しつづけロボットの技術を成長させてきた
* 完走しているチームの技術力は非常に高い
* 初めて参加するチームや個人で参加するチームとは技術的な差が大きい
   * 初参加から完走するまでの道のりは遠い
   * その要因は以下の点であると感じた
      * 完走しているチームの多くは高価な3DLiDARを搭載している
      * ROS 2を使用した3Dナビゲーションのノウハウがウェブ上にあまり公開されていない
      * つくばチャレンジレポートは昨年のレポートの差分が書かれていることが多い
      * つくばチャレンジレポートは特定の課題の解法が書かれていることが多い
      * つくばチャレンジレポートは過去のレポートがオープンになっていないため，引用先が見られない
   * 以上の点から，初学者や新規参入者に対して敷居が高いように感じた
* 同時に，完走するために必要なことは以下のように感じた
   * 屋外の自律走行には初学者ほど3DLiDARがあった方がよい
   * 複雑なシステムを運用するには，質の良いハードウェアが必要である
   * OSSを駆使すればある程度まではロボットを動作させることができる
   * OSSを利用するだけでは完走には至らない
* AbudoriLab.チームでは，本走行では確認走行区間をクリアできなかった
   * 他のロボットが通路を塞いだため新ルートを作れなかった
* 決められたルートに何も障害物がない状態であれば，もっと走行することができた
* 決められたルートを走行することだけであれば，自己位置を喪失することなく，障害物も発見し走行することができた
* ゼロからつくばチャレンジに参加する人に必要なことがわかるレポートにしたい
* AbudoriLab.が用意したロボットやソフトウェア構成を紹介する

# システムアーキテクチャ
* 自律走行システムのハードウェア（吉田）
   * 自律走行ロボットにはさまざまな部品が必要である
   * 具体的は以下の通り
      * センサ
         * 自己位置推定LiDAR
            * 高い位置に設置
            * 囲まれても遠くの建物が映るように
         * 障害物検知LiDAR
            * 地面がわざと映るようにななめ設置
            * LiDARから地面にある障害物の最短距離が0.3mで検知できるように設置
         * ロボットシャーシ
            * クローラロボット開発プラットフォームを採用した
         * 電源
            * 各デバイスが動作するようにバッテリーから変圧して配電している
   * ロボットハードウェアの構成
      * 図
   * 分解して持ち運べる部品構成
      * 大きく分けて以下の部品で分解できる
         * ロボットシャーシ
         * PC
         * 筐体
         * センサ
      * 他に工夫した点があれば
      * 図があれば
   * ロボットの走行状態の表示機能（村上）（書きたければ）
      * LEDによる意思表示
      * 他に工夫したことがあれば
      * 図があれば

* 自律走行システムのソフトウェア
   * ロボットを走行させるためのソフトウェア構成は以下の通りである
      * 地図作成
         * ロボットの活動範囲内は既知の場所
         * 現実の場所とリンクした地図をロボットに持たせる
         * 自己位置推定に使用する
      * 自己位置推定
         * 現在の位置がロボットが持っている地図のどこに位置するのか推定する
         * 現在位置が分かれば，目的までの向かう経路を計算することができる
      * 障害物認識
         * 自己位置推定ができても，実際には障害物があってたどり着かないことがほとんどだ
         * 向かいたい場所までの経路上に障害物がどのようにあるのか反映させる
      * 経路計画
         * ロボットは地図をもっているので目的地点と現在位置があれば2点間の経路を計算できる
         * このとき，環境上にある障害物も加味し，障害物に衝突しない経路を計算する
         * 実際の自律走行では，数メートルおきに達成地点を設置し，細かく経路計画を実施する
      * 経路追従
         * 計算した経路にロボットを追従させる
         * 障害物を回避しながら，柔軟に経路通りにロボットを制御させる必要がある
   * 次の章から，それぞれの方法で具体的に使用したソフトウェアを紹介する

# 地図作成
* 現代の自律走行の大半は，ロボットの行動範囲の環境地図を作成する．
* 作成した環境地図をロボットが持つことにより，既知の環境内で自由に行動することを目指す
* ROS 2標準のNavigation2の標準アルゴリズムも含め環境地図は2Dのものが多い
* 2D地図は室内など水平であり障害物が単純な環境であれば，とてもよく動作する
* しかし，屋外や広大な環境だと以下のような点でうまくいないことがある
   * 設置した2DLiDARの設置高さによっては検知できない障害物が多く，無視できないことがある
   * 上り坂など，本来障害物でないものも障害物として認識することがある
   * 2D地図で表現しきれない障害物が重要な物体であった場合，精度が大幅に悪化する
   * 自動車が止まったりするなど環境の変化があると大きく悪影響を受けることがある
* このつくばチャレンジ2024では，3Dの地図を作成し，上記のポイントで複雑な環境でもうまく地図表現をした
* 回転式3DLiDARは非常に高価であるが，つくばチャレンジでは，無料貸与がある
   * つくばチャレンジ2024では，株式会社アルゴさまより無料で貸与いただいた
   * もっていない人でも3DLiDARに挑戦することができる
   * ぜひやっていただきたい
* 地図作成には，回転式3DLiDARで，GLIM（引用）を用いて作成した
* 作成したつくばチャレンジの走行範囲全域の地図は図の通りである
   * 図
* 環境構築をした後，全周のルートを走行させた時のロボットの回転式3DLiDARのセンサデータを記録したROSBAGファイルを再生するだけで3D地図が作成できてしまった
* 設定にチューニングとしては以下の点である
   * あああ
   * いいい
   * ううう
* AAAの点では，あああパラメータが効く
* BBBの点では，いいいパラメータが効く
* CCCの点では，うううパラメータが効く
* XXXという点に注意してパラメータチューニングするとよい
* 最後に，オフライン地図修正ツールが同梱されているのでこれで地図を微修正する
* ループクローズがうまくハマるように指定する
* つくばチャレンジ全域で自己位置推定ができる地図ができた
* 3D地図はhttps://google-drive で公開しているので，来年同じ構成で使用したい方は使うと良い．

# 自己位置推定
* 前章で作成した3D地図に対して，ロボットの自己位置を表現する
* 3D地図で自己位置推定することで，2D地図よりも以下の点で優れていると考えたため採用した
  * トラックのような大きな障害物がある場合でも自己位置が破綻しない
  * 2D地図の場合はバンが止まっている場所に近づいた時，位置が飛んでしまった
  * 2D地図の場合はロボットの周辺に人だかりがあるとマッチングできない
  * 2D地図の場合は坂道のように地面が2DLiDARに映る場合，位置が飛んでしまった
* 後述のNavigationでは，2Dを利用する
  * 地面を走行するロボットであるため，2Dの姿勢で十分
  * 3Dで自己位置推定して，そのうちX,Y,Yawだけを抽出して利用する
* 自己位置推定手法としては，OSSのLidar_localization_ros2を利用した
  * 前章で作成した3D地図をpcdに変換して読み込んだ
  * 地図はコンフィグファイルに絶対パスを書き込むだけ読み込まれる
  * LiDARを起動した状態で自己位置推定アルゴリズムを起動する
  * 起動した後に初期位置を与える
  * コンフィグで初期設定を与えることもできる
  * 初期姿勢と地図のマッチングが成功すると常にLiDARスキャンマッチをつづけて自己位置を更新し続ける
* 設定にチューニングとしては以下の点である
  * あああ
  * いいい
  * ううう
  * AAAの点では，あああパラメータが効く
  * BBBの点では，いいいパラメータが効く
  * CCCの点では，うううパラメータが効く
  * XXXという点に注意してパラメータチューニングするとよい
* 以下の点で自己位置が破綻することがある
  * あああ
  * いいい
  * ううう
* オドメトリをオンにすることでふっとびを抑えることができた
* IMUはチューニング不足で破綻してしまった
* 結果的にXXXに注意すると良い

# 障害物認識
* 自己位置とゴールが分かればロボットが進むべき経路を計算できる
* ただし，これだけでは現実にある衝突してはいけない障害物を考慮していない
* LiDARなどのセンサを使って障害物を認識し，それを地図に反映させることで障害物を考慮した経路を計算できる
* 多くのロボットでは，2DLiDARを障害物に使用している
* 2DLiDARを使うと坂道など地面が写ってしまう
* 2DLiDARを使うと机のような物体は脚しか映らない
* 3DLiDARを使うことで机の柱と天板の部分の全体の点群を得ることができる
* 2DLiDARと異なり，ぶつかりたくない部分を抽出して点群として表現できる
* メカの章に載せた，MID360でを使用した
* これを実現するROSパッケージを作成した．
* 簡単な手順としては以下の通りだ
  * 点群をダウンサンプリングする
  * LiDAR点群の傾きを設置角度から逆算して水平にする
  * 法線を各点ごとに計算する
  * 法線ベクトルから水平なものは地面など問題ないものと判断した
  * 法線ベクトルから垂直に近いものは壁や障害物と判断した
  * 計算を単純にするために，法線のZ方向で閾値で区切った
  * これで坂道や乗り越え可能な5cm程度の小物は水平と判断し障害物判定できた
  * 細い鉄パイプやパイロンの根本も障害物として判定できた
* 出力した点群をOSSのPointCloudToLaserScanパッケージに入力し，2DLiDARのscanトピックに変換した
* このScanトピックをNavigation2に入力することで，広く使われる2DLiDARのサンプルをそのまま動かすことができた．
* つくばチャレンジ環境で使用してパイロンや人，生垣などの大半の障害物を検出することができた
* パイロンは先端の細いところから根本の一番太いところまで観測できた．
  * この方式では，パイロンの一番太いところをScanとして出力するため，パイロンのぎりぎりを通過することがすくない
* 苦手な物体として，背のひくい水平な障害物は検出することが難しい
  * 平台車
  * 小さな段ボール
  * 地面成分が大きく平均化され溶け込んでしまう
* 2.4GHz CPUシングルスレッドで40msくらい
* ８スレッドで分散処理して7msくらい
* PCの電飾消費が深刻だったので，あえてシングルスレッドの実装で走行した
* パッケージはOSSで公開しているので，ぜひ利用してほしい
# 経路計画（中村案）
* ROS 2では，経路計画パッケージとしてNavigation2がある
* 環境地図と自己位置を入力すれば，指定したゴール座標までの経路を出力してくれる
* 計算アルゴリズムの手法が複数用意されている
* 各手法がPluginとして実装されており，コンフィグファイルでPlugin名を変更するだけで反映される
* つくばチャレンジ2024では，3DMapを利用して自己位置推定を行なった．
* Navigation2にはMapを入力せず，３DMapからの自己位置推定のX,Y,Yawの値をそのまま利用するだけで２Dに転写した．
* Navigaiton2には作成したObstacleToScanから2DLiDARを模擬したscanトピックを入力した．
* これで２DMapはないが，ロボット周辺の障害物マップは作成される
* これで，ロボットから２〜１０m程度の距離にゴールを指定することで短距離の経路を計算してくれる
* この短距離で達成できるゴールを数メートルおきに，完走のゴールまで配置しつづける
* 近くのゴールが達成できれば，次のゴールを設定する処理を自動化した．
* これがPenguin_Nav
* penguin_navはお願いします．
* 
* SmacPlanner
* 経路計画方法はSmacPlannerを利用した．
* SmacPlannerはNavigation2のPluginに実装されているため，ConfigファイルでSmacPlannerを選択するだけで利用できる．
* SmacPlannerはロボットの形状を考慮した衝突判定をしてくれる
* したがって，自ロボットの投影面積であるポリゴンを指定するだけで，無茶な経路は選ばれなくなる
* また，最小回転半径も指定できるため，なめらかな円弧で走行経路を利用できる
* これにより，障害物ギリギリまで近づいて急に避ける行動を抑えることができた．
# 経路計画（青木）
* penguin_nav
  * CSVファイルで記述された経路データを解釈し，simple commander API 経由で navigation に経路を渡す
  * simple commander APIだけでは以下の問題があった
    * 広い領域を走行するためには広い grid map を予め作る必要があった
    * ゴールが障害物で埋まると経路計画に失敗する
    * ある地点は走り抜ける，ある地点では一時停止しキー入力待ちをするなどの行動選択ができない
    * 長大なパス追従を要求すると，パス計算に時間がかかる
    * etc.
  * ソフトで実現したもの
    * parameter reconfigure (正式名称要確認) を使用して動的に grid map のサイズ，オフセットを変更できるようにする
    * ロボットの位置を取得し，grid map の再計算で使用できるようにする
    * パスの分割，及び各点でのアクションの仕様を作成
    * grid map はロボットの現在位置，分割されたパスを包含するように調整される
    * キー入力待ち
    * Ctrl+C による graceful shutdown
    * waypoint が障害物に埋まった時に対応できるよう，waypoint の横位置を調整するサーバー
    * waypoint の rviz での可視化
  * ソフト的な問題
    * simple commander API は内部的に executor を使用していて，他の executor (rclpy.spin など) の中で使用することができない
    * キー入力が同期APIで，実際に入力され enter が押されるまで処理をブロッキングしてしまう
    * 非同期処理が必要だが，Python 3.10 の asyncio では keyboard interrupt を上手く処理できない
* waypoint modifier
  * ロボットを走行させるためには目標となるパスを用意する必要がある
    * そのためにパスの生成，及び可視化ができる周辺ツールを作成した
  * resampler
    * パスは，試験走行時に手動操縦で走らせた時の軌跡に基づいて作成した
    * この軌跡は SLAM により計算されたものだが，非常に密度が高く，間引く必要があった
      * 間引きは，ある程度の間隔でサンプリングする，ただし，急カーブなどは，カーブに沿って追従してほしいためある程度高密度に，という意図に基づいて行いたい
    * resmpler は以下の値に基づいてサンプリングを行う
      * ...
  * viewer
    * resampler で生成したパスはある程度間引かれたものだが，走行にそのまま使用するのには適していない
      * 手動操縦時に発生した意図しない動きがそのまま反映されている
      * SLAMの誤差によりノイズが乗った軌跡が残ってしまう
      * 手動走行時とは少しずれた位置を走行させてい場合がある
      * 一時停止など，課題に必要な行動内容を追加する必要がある
    * これを加味した自動サンプリングアルゴリズムを開発するのは難しいため，CSVファイルを手で編集する必要があるが，CSVファイルをテキストエディタだけで編集するのは効率的ではない
    * そのためCSVファイル編集を支援するブラウザ可視化ツールを開発した
    * 機能
      * CSVのパスデータの2Dプロット
      * 行動に応じた色分け
      * CSVファイルを監視することによるリアルタイム更新
      * パン，ズームなどの操作，及び点の座標などの情報の表示
      * 点の位置の微調整のため，重畳表示する点列データも可視化する機能(元ネタのslamデータを表示するなど)
      * ブラウザ上での読み込みファイル選択
    * 技術的には以下のライブラリを使用している
      * plotly
      * plotly-dash
* penguin_nav (launch)
  * navigation 2 を使用して経路計画及びコントロールを行った
  * planner
  * controller
  * obstacle avoidance

# 経路追従
* 前節のSmacPlannerで計算された経路をロボットがどのように再現するか計算するアルゴリズムを経路追従アルゴリズムという
* Navigation2では，さまざまな経路追従アルゴリズムを利用できる
* つくばチャレンジ2024では，DWBをつかった
* DWBはロボットが再現可能な速度や加速度の範囲の中で一番良い速度を選択する
* 最高速度と最低速度と加速度を設定できる
* クローラの制御の場合，抵抗が非常に大きく初動に大きなエネルギーを必要とする
* 最低速度を速く設定し，すぐに停止できるように減速加速度を大きくなるように設定した．
* ほか設定項目を確認
# 本走行（考察）
* 以上の構成で３DLiDARを利用した自律走行システムを構築した
* つくばチャレンジ2024の本走行では，市庁舎裏の細い通路でロボットを回避し，元の経路に再計画できずにリタイアした．
* それまでの走行は，自己位置を見失うこともなく，障害物を未検出になることなく動作した．
* 障害物からは距離を1m程度離れるように設定していたため，狭路では，非常に慎重にゆっくりゆっくり進んだが，走行経路はブレることはなかった．
* このロボットは設定したルートに忠実になぞる機能しか搭載していなかった
* 他ロボットが決められた道を長時間塞いでしまった時，迂回する機能は搭載されていなかったため，復帰できず終了した
* 本年は決められた座標の通りに走行する機能までは３DLiDARを使って実現することができた
# 結論
* つくばチャレンジ2024では，３DLiDARを利用したナビゲーションシステムを構築することができた
* ３DLiDARのナビゲーションシステムは文献が少なく構築することに苦労したが，最低限の機能を揃えることはできた
* つくばチャレンジの多くのロボットは３DLiDARを利用しているが，何から手をつければ良いかわからない人はいるはずである
* このレポートでは，ハードウェアから自律ナビゲーションシステムの各機能のおおよその仕組みを述べた
* 来年初参加を考えている人の参考になれば幸いである
* 環境構築の方法や実際の詳細の使用方法などは引き続きブログで解説していく予定である．
* 次年度では，決められたルートを走行する上での意思決定機能を追加で実装する
* 完走するためには，不測の事態でも，認知判断行動することが必須である
* 完走にむけてナビゲーションシステムをブラッシュアップしていく予定である．
# 謝辞
