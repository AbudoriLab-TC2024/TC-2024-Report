\section{障害物認識}
自己位置とゴールが分かればロボットが進むべき経路を計算できる。
ただし、これだけでは現実にある衝突してはいけない障害物を考慮していない。
LiDARなどのセンサを使って障害物を認識し、それを地図に反映させることで障害物を考慮した経路を計算できる。
多くのロボットでは、2DLiDARを障害物に使用している。
2DLiDARを使うと坂道など地面が写ってしまう。
2DLiDARを使うと机のような物体は脚しか映らない。
3DLiDARを使うことで机の柱と天板の部分の全体の点群を得ることができる。
2DLiDARと異なり、ぶつかりたくない部分を抽出して点群として表現できる。
メカの章に載せた、MID360でを使用した。
これを実現するROSパッケージを作成した。
簡単な手順としては以下の通りだ。
点群をダウンサンプリングする。
LiDAR点群の傾きを設置角度から逆算して水平にする。
法線を各点ごとに計算する。
法線ベクトルから水平なものは地面など問題ないものと判断した。
法線ベクトルから垂直に近いものは壁や障害物と判断した。
計算を単純にするために、法線のZ方向で閾値で区切った。
これで坂道や乗り越え可能な5cm程度の小物は水平と判断し障害物判定できた。
細い鉄パイプやパイロンの根本も障害物として判定できた。
出力した点群をOSSのPointCloudToLaserScanパッケージに入力し、2DLiDARのscanトピックに変換した。
このScanトピックをNavigation2に入力することで、広く使われる2DLiDARのサンプルをそのまま動かすことができた。
つくばチャレンジ環境で使用してパイロンや人、生垣などの大半の障害物を検出することができた。
パイロンは先端の細いところから根本の一番太いところまで観測できた。
この方式では、パイロンの一番太いところをScanとして出力するため、パイロンのぎりぎりを通過することがすくない。
苦手な物体として、背のひくい水平な障害物は検出することが難しい。
平台車。
小さな段ボール。
地面成分が大きく平均化され溶け込んでしまう。
2.4GHz CPUシングルスレッドで40msくらい。
８スレッドで分散処理して7msくらい。
PCの電飾消費が深刻だったので、あえてシングルスレッドの実装で走行した。
パッケージはOSSで公開しているので、ぜひ利用してほしい。